# tasks: ['pick_up_cup'] # ['pick_up_cup', 'pick_and_lift', 'push_button', 'reach_target', 'take_lid_off_saucepan']
10_tasks:  [pick_up_cup,phone_on_base,pick_and_lift,put_rubbish_in_bin,push_button,reach_target,lamp_on,take_lid_off_saucepan,take_umbrella_out_of_umbrella_stand,stack_wine]
run_name: burn 
mt_only:  True # True for no context, MT policy 
log_path: ??? 
tasks_name: ???

method: ??? 
tasks:
  all_tasks: [push_button]
  cameras: [front]
  num_vars: -1 
  heldout: ''
  demo_length: 1 
  train_steps: 10000
  log_freq:   100 

rlbench: 
    tasks: ${tasks}
    all_tasks: ???       # [task_A, task_B,...]
    use_variations: ??? # [ [task_A_0], [task_B_0], ...
    all_variations: ???  # [ [task_A_0, task_A_1,...], [task_B_0, ...] ]
    id_to_tasks: ??? 
    demos: 0
    demo_path: /homed
    episode_length: 10
    cameras: ${tasks.cameras}
    camera_resolution: [128, 128]
    scene_bounds: [-0.3, -0.5, 0.6, 0.7, 0.5, 1.6]
    max_fails: 5
    single_variation: False 
    num_vars: ${tasks.num_vars}

replay:
    batch_size: 60 # total buff size, no task-aggregate anymore 
    total_batch_size: 10000
    timesteps: 1
    prioritisation: True
    use_disk: False
    path: '/tmp/arm_sanity/replay'  # Only used when use_disk is True.
    share_across_tasks: True
    replay_size: 100000 # total size 
    update_buffer_prio: True 
    buffers_per_batch: 1
    num_tasks_per_batch: -1
    num_vars_per_batch: -1 
    # ? make sure the multi-var tasks get multiple vars

framework:
    log_freq:  ${tasks.log_freq} # set to bigger to not save so many media files 
    save_freq: 100
    train_envs: 1
    eval_envs: 2
    env_runner_gpu: 1
    replay_ratio: 30
    transitions_before_train: 100
    tensorboard_logging: True
    csv_logging: False
    wandb: True
    training_iterations: ${tasks.train_steps}
    eval_episodes: 2000
    gpu: 0
    logdir: '/home/mandi/ARM/irl/log/'
    seeds: 1
    resume: ${resume}
    resume_path: ${resume_path}
    resume_run: ${resume_run}
    resume_step:  ${resume_step}
    resume_dir: ''
    resume_freeze: ${resume_freeze}
    log_all_vars: False
    switch_online_tasks: 0
    num_log_episodes: 10  # NOTE: also use this to count ckpt eval episodes!!
    ckpt_eval: False 
    
rew:
  task_reward: False
  data_path: '/home/mandi/ARM/irl/CLIP_ARM/'
  model_path: /home/mandi/ARM/irl/clip-tuned/
  task_name: push_button
  model: 'demo_only_256x512'
  step: 100
  prompts: ["robot gripper tip touch square button"]
  save_data: False 
  overwrite: True
  save_itr: 0 
  use_aug: False
  aug_avg: 1
  predict_logits: False
  scale_logits: False
  shift_t: True

resume: False
resume_path: '/home/mandi/ARM/log/' # or: /shared/mandi/arm_log 
resume_run: ''
resume_step: 24300
resume_freeze: []

dev:
    q_thres: 0.75  
    qagent_update_context: True
    qagent_use_emb_loss: True # for ablation set to False 
    one_hot: False 
    noisy_one_hot: False 
    noisy_dim_20: False 
    encode_context: True  # if one-hot, prolly ok not to encode
    qnet_context_latent_size: 16
    encode_context_hidden: -1
    cat_down1: False
    cat_down2: False
    cat_up1: False 
    cat_up2: False
    cat_f1: False
    cat_final: False
    conv3d: False 
    handpick: [] # [0,3,4,6,7,10,11,16,18,19] or, [0,3,4,6,10] for red, green,blue,yellow,gray
    # exclude similar colors: red, green,blue,yellow,cyan,gray,orange,violet,black,white
    # exclude gray and white: [0,3,4,6,7,11,16,18]
    offline: False 
    eval_only: False
    freeze_emb: False  
    single_layer_context: True # check with False 
    use_film: False 
    qnet_2_layer_context: False 
    classify: False
    emb_weight: 0
    freeze_after_steps: -1 
    replay_update_freq: 1 # skip rep. loss during replay update! 
    discrete: False  # dVAE context agent
    discretise: False # for gumbel smax
    ctxt_conv3d: False 
    batch_sample_mode: ''
    use_reptile: False 
    use_anil:  False 
    reptile_eps: [1,0] # [initial, final]
    reptile_k: 5 
    normalize_reward: ''  
    grad_accum: 1 
    augment_batch: 0 
    # '/home/mandi/ARM/clip-tuned/1mlp-256/300.pt' , '/home/mandi/ARM/clip-tuned/2mlps-256x512-360episodes/1750.pt'
    # diff objective: 2mlps-256x512step0-TrajImprove-iteration0/200.pt
    # next up no scale: /home/mandi/ARM/clip-tuned/2mlps-256x512-NoScale-NoExpertloss-TrajImprove-iteration4/2150.pt 



wandb:
    project: 'ContextARM'
    entity:    mannndi
    job_type: 'launch'
    group:    'irl'
hydra:
    run:
        dir: ${framework.logdir}/ #${rlbench.task}/${method.name}
